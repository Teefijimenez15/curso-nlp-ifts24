{"cells":[{"cell_type":"markdown","metadata":{"id":"intro-header"},"source":["# Introducci√≥n a los Embeddings de Texto con Modelos Abiertos\n","\n","Este cuaderno te ense√±ar√° los conceptos fundamentales de los **embeddings de texto** usando modelos abiertos disponibles en Hugging Face. Los embeddings son representaciones num√©ricas de palabras o frases que capturan su significado sem√°ntico de manera que las computadoras puedan procesarlo.\n","\n","## ¬øQu√© vas a aprender?\n","\n","1. **Qu√© son los embeddings** y por qu√© son √∫tiles en el procesamiento de lenguaje natural\n","2. **C√≥mo generar embeddings** usando modelos pre-entrenados abiertos\n","3. **Calcular similitudes** entre textos usando embeddings\n","4. **Diferencias** entre embeddings de palabras y de oraciones\n","5. **Aplicaciones pr√°cticas** de los embeddings\n","6. **Comparar diferentes modelos** para encontrar el mejor para espa√±ol\n","\n","## Ventajas de usar modelos abiertos\n","\n","- **Gratuitos**: No hay costos por uso como con APIs comerciales\n","- **Transparentes**: Pod√©s inspeccionar y entender c√≥mo funcionan\n","- **Personalizables**: Los pod√©s afinar para tu dominio espec√≠fico\n","- **Privacidad**: Tus datos no salen de tu computadora"]},{"cell_type":"markdown","metadata":{"id":"setup-header"},"source":["## Configuraci√≥n del Entorno\n","\n","Primero instalamos las librer√≠as necesarias. Vamos a usar:\n","- **sentence-transformers**: Para generar embeddings de alta calidad\n","- **scikit-learn**: Para calcular similitudes\n","- **numpy**: Para manipulaci√≥n de arrays\n","- **ipywidgets**: Para interfaces interactivas\n","\n","Si est√°s corriendo esto localmente, descoment√° la siguiente l√≠nea:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"install-deps","executionInfo":{"status":"ok","timestamp":1760828354640,"user_tz":180,"elapsed":5658,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}}},"outputs":[],"source":["!pip install sentence-transformers scikit-learn numpy ipywidgets -q"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"import-libs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828354654,"user_tz":180,"elapsed":11,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"5a53afb3-b940-41fb-a38c-b3e1a0447587"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Librer√≠as importadas correctamente\n"]}],"source":["# Importamos las librer√≠as necesarias\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity #me permite calcular la similitud de coseno\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')  # Silenciamos warnings menores\n","\n","print(\"‚úÖ Librer√≠as importadas correctamente\")"]},{"cell_type":"markdown","metadata":{"id":"model-selection"},"source":["## Selecci√≥n del Modelo\n","\n","Vamos a usar un modelo pre-entrenado que funciona bien con espa√±ol. Te mostramos varias opciones:\n","\n","1. **`paraphrase-multilingual-MiniLM-L12-v2`**: R√°pido, funciona bien con espa√±ol\n","2. **`distiluse-base-multilingual-cased`**: Buena calidad, multiidioma\n","3. **`all-MiniLM-L6-v2`**: Muy r√°pido, principalmente ingl√©s pero funciona con espa√±ol. Generalmente es el que trae por defecto\n","\n","Empezamos con el modelo multiling√ºe que da buenos resultados en espa√±ol:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"load-model","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357246,"user_tz":180,"elapsed":2591,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"84333536-1975-4a9f-9053-e178cb7eda12"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Modelo cargado: sentence-transformers/distiluse-base-multilingual-cased-v2\n","üìä Dimensi√≥n de los embeddings: 512\n"]}],"source":["# Cargamos el modelo de embeddings\n","modelo_nombre = 'sentence-transformers/distiluse-base-multilingual-cased-v2'\n","modelo_embeddings = SentenceTransformer(modelo_nombre)\n","\n","print(f\"‚úÖ Modelo cargado: {modelo_nombre}\")\n","print(f\"üìä Dimensi√≥n de los embeddings: {modelo_embeddings.get_sentence_embedding_dimension()}\")"]},{"cell_type":"markdown","metadata":{"id":"first-embedding"},"source":["## Tu Primer Embedding\n","\n","Vamos a generar el embedding de una palabra simple y ver qu√© aspecto tiene:\n","En este caso para la palabra vida. El embedding tiene una longitud de 512, 512 dimensiones imposible de representar y aca muestro los primeros 10 valores."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"word-embedding","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357266,"user_tz":180,"elapsed":15,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"aed18446-41ae-40c0-b49f-5d69ae2266b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra: 'vida'\n","Longitud del embedding: 512\n","Primeros 10 valores: [ 0.01135431  0.03165706  0.0005522  -0.00983733 -0.05544117 -0.02832641\n"," -0.04866723 -0.01849577 -0.02111436 -0.06133432]\n","Tipo de datos: <class 'numpy.float32'>\n"]}],"source":["# Generamos el embedding de una palabra\n","palabra = \"vida\"\n","embedding = modelo_embeddings.encode([palabra])\n","\n","print(f\"Palabra: '{palabra}'\")\n","print(f\"Longitud del embedding: {len(embedding[0])}\")\n","print(f\"Primeros 10 valores: {embedding[0][:10]}\")\n","print(f\"Tipo de datos: {type(embedding[0][0])}\")"]},{"cell_type":"markdown","metadata":{"id":"embedding-explanation"},"source":["### ¬øQu√© acabamos de ver?\n","\n","- **Un embedding es un vector**: Una lista de n√∫meros que representa el significado de la palabra\n","- **Dimensionalidad fija**: Todos los embeddings tienen la misma longitud (384 en este modelo)\n","- **N√∫meros decimales**: Los valores pueden ser positivos o negativos, generalmente entre -1 y 1\n","- **Significado distribuido**: Cada dimensi√≥n captura alg√∫n aspecto del significado"]},{"cell_type":"markdown","metadata":{"id":"sentence-embedding"},"source":["## Embeddings de Oraciones\n","\n","Los modelos modernos pueden generar embeddings que representan oraciones completas, teniendo en cuenta el contexto y el orden de las palabras.\n","\n","Pasamos de la construcci√≥n de embeddings de palabras a la construcci√≥n de embeddings de oraciones.\n","Es decir, ya no representamos solo el significado de cada palabra individualmente, sino que creamos una representaci√≥n num√©rica del sentido completo de una oraci√≥n.\n","\n","Cada oraci√≥n se transforma en un vector denso, por ejemplo, de 512 dimensiones.\n","Cada uno de esos 512 valores num√©ricos intenta capturar una parte del significado general de la oraci√≥n, representando distintos aspectos sem√°nticos y contextuales.\n","\n","Para que estas oraciones se transformen en vectores, utilizamos el modelo que vimos antes, que es el encargado de crear estas representaciones num√©ricas.\n","No todos los modelos generan embeddings con la misma cantidad de dimensiones:\n","hemos visto modelos con 50, 200, 300 o incluso 500 caracter√≠sticas.\n","\n","Cada modelo, dentro de su extensi√≥n, intenta capturar el m√°ximo de informaci√≥n sem√°ntica posible.\n","En general, cuantas m√°s dimensiones tenga un embedding, m√°s capacidad tendr√° para representar matices del significado.\n","\n","El modelo nos ayuda porque est√° especialmente afinado para trabajar en espa√±ol,\n","y funciona como un cerebro que contiene la estrategia para traducir el texto en vectores,\n","es decir, en representaciones num√©ricas.\n","\n","Lo hace en funci√≥n de todos los par√°metros que ya tiene aprendidos durante su entrenamiento,\n","lo que le permite interpretar y codificar el sentido de una oraci√≥n completa dentro del espacio vectorial."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"sentence-embed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357276,"user_tz":180,"elapsed":7,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"32f9c616-cc4f-48c4-b540-3ad36788b273"},"outputs":[{"output_type":"stream","name":"stdout","text":["Oraci√≥n: '¬øCu√°l es el sentido de la vida?'\n","Longitud del embedding: 512\n","Primeros 10 valores: [ 0.01623319 -0.04003485  0.03519869  0.00145082 -0.07798815 -0.04161033\n"," -0.04850182  0.00988518 -0.00833548 -0.11256867]\n"]}],"source":["# Generamos el embedding de una oraci√≥n completa\n","oracion = \"¬øCu√°l es el sentido de la vida?\"\n","embedding = modelo_embeddings.encode([oracion])\n","\n","print(f\"Oraci√≥n: '{oracion}'\")\n","print(f\"Longitud del embedding: {len(embedding[0])}\")\n","print(f\"Primeros 10 valores: {embedding[0][:10]}\")"]},{"cell_type":"markdown","metadata":{"id":"similarity-intro"},"source":["## Calculando Similitudes\n","\n","Una de las aplicaciones m√°s √∫tiles de los embeddings es medir qu√© tan similares son dos textos. Usamos la **similitud coseno**, que va de 0 (nada similar) a 1 (id√©ntico).\n","\n","Probemos con tres oraciones de diferente similitud:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"similarity-calc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357285,"user_tz":180,"elapsed":7,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"111837f7-a7c7-4063-9ae4-3032c8d8e83b"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Comparando similitudes:\n","Oraci√≥n 1: '¬øCu√°l es el sentido de la vida?'\n","Oraci√≥n 2: '¬øC√≥mo podemos vivir una vida plena y significativa?'\n","Oraci√≥n 3: '¬øTe gustar√≠a una ensalada?'\n","\n","üìä Similitud entre Oraci√≥n 1 y 2: 0.613\n","üìä Similitud entre Oraci√≥n 1 y 3: 0.171\n","üìä Similitud entre Oraci√≥n 2 y 3: 0.077\n"]}],"source":["# Definimos tres oraciones para comparar\n","oracion_1 = \"¬øCu√°l es el sentido de la vida?\"\n","oracion_2 = \"¬øC√≥mo podemos vivir una vida plena y significativa?\"\n","oracion_3 = \"¬øTe gustar√≠a una ensalada?\"\n","\n","# Generamos los embeddings\n","emb_1 = modelo_embeddings.encode([oracion_1])\n","emb_2 = modelo_embeddings.encode([oracion_2])\n","emb_3 = modelo_embeddings.encode([oracion_3])\n","\n","print(\"üîç Comparando similitudes:\")\n","print(f\"Oraci√≥n 1: '{oracion_1}'\")\n","print(f\"Oraci√≥n 2: '{oracion_2}'\")\n","print(f\"Oraci√≥n 3: '{oracion_3}'\")\n","print()\n","\n","# Calculamos similitudes\n","sim_1_2 = cosine_similarity(emb_1, emb_2)[0][0]\n","sim_1_3 = cosine_similarity(emb_1, emb_3)[0][0]\n","sim_2_3 = cosine_similarity(emb_2, emb_3)[0][0]\n","\n","print(f\"üìä Similitud entre Oraci√≥n 1 y 2: {sim_1_2:.3f}\")\n","print(f\"üìä Similitud entre Oraci√≥n 1 y 3: {sim_1_3:.3f}\")\n","print(f\"üìä Similitud entre Oraci√≥n 2 y 3: {sim_2_3:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"similarity-analysis"},"source":["### Interpretando los Resultados\n","\n","- **Alta similitud (>0.7)**: Los textos tratan temas muy relacionados\n","- **Similitud media (0.3-0.7)**: Hay alguna relaci√≥n sem√°ntica\n","- **Baja similitud (<0.3)**: Los textos son sobre temas diferentes\n","\n","¬øLos resultados coinciden con tu intuici√≥n? Las primeras dos oraciones deber√≠an ser m√°s similares entre s√≠ que con la tercera."]},{"cell_type":"markdown","metadata":{"id":"word-vs-sentence"},"source":["## Embeddings de Palabras vs. Embeddings de Oraciones\n","\n","Vamos a explorar la diferencia entre promediar embeddings de palabras individuales y generar embeddings de oraciones completas. Esto te ayudar√° a entender por qu√© los modelos modernos son mejores.\n","\n","Usemos dos oraciones que tienen las mismas palabras pero significados diferentes:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"context-example","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357330,"user_tz":180,"elapsed":43,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"0e042c6f-bfaa-49e7-f446-363bb62216ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Oraci√≥n 1: 'Los ni√±os juegan en el parque'\n","Oraci√≥n 2: 'La obra de teatro fue para ni√±os en el parque'\n","\n","Palabras clave extra√≠das: ['ni√±os', 'juegan', 'parque', 'obra', 'teatro']\n"]}],"source":["# Dos oraciones con las mismas palabras pero diferente significado\n","oracion_1 = \"Los ni√±os juegan en el parque\"\n","oracion_2 = \"La obra de teatro fue para ni√±os en el parque\"\n","\n","print(f\"Oraci√≥n 1: '{oracion_1}'\")\n","print(f\"Oraci√≥n 2: '{oracion_2}'\")\n","print()\n","\n","# Palabras clave (sin art√≠culos, preposiciones, etc.)\n","palabras_clave = [\"ni√±os\", \"juegan\", \"parque\", \"obra\", \"teatro\"]\n","print(f\"Palabras clave extra√≠das: {palabras_clave}\")"]},{"cell_type":"markdown","metadata":{"id":"word-averaging"},"source":["### M√©todo 1: Promediando Embeddings de Palabras\n","\n","Este es el m√©todo \"naive\" - simplemente promediamos los embeddings de cada palabra:"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"avg-method","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357385,"user_tz":180,"elapsed":52,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"ba370911-5fad-43f9-93f9-a2377c6305c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Forma del array de embeddings: (5, 512)\n","(Tenemos 5 palabras, cada una con 512 dimensiones)\n","\n","Forma del embedding promedio: (512,)\n","Primeros 5 valores: [ 0.00228814  0.01959183 -0.04456261 -0.02483301 -0.03985602]\n"]}],"source":["# Generamos embeddings para cada palabra individualmente\n","embeddings_palabras = modelo_embeddings.encode(palabras_clave)\n","print(f\"Forma del array de embeddings: {embeddings_palabras.shape}\")\n","print(f\"(Tenemos {len(palabras_clave)} palabras, cada una con {embeddings_palabras.shape[1]} dimensiones)\")\n","\n","# Calculamos el promedio\n","embedding_promedio = np.mean(embeddings_palabras, axis=0)\n","print(f\"\\nForma del embedding promedio: {embedding_promedio.shape}\")\n","print(f\"Primeros 5 valores: {embedding_promedio[:5]}\")"]},{"cell_type":"markdown","metadata":{"id":"sentence-method"},"source":["### M√©todo 2: Embeddings de Oraciones Completas\n","\n","Ahora usamos el modelo para generar embeddings que consideran el contexto y el orden:"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"sentence-method-code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357430,"user_tz":180,"elapsed":47,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"45c8fc48-6b6e-405b-c4e3-6183b6527db7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Embeddings de oraciones completas:\n","Oraci√≥n 1 - Primeros 5 valores: [ 0.00424555  0.08126318 -0.06567939 -0.00210191  0.03611833]\n","Oraci√≥n 2 - Primeros 5 valores: [ 0.00119551  0.07684387 -0.05929851 -0.00911988  0.01148098]\n","\n","üìä Similitud entre las oraciones: 0.694\n"]}],"source":["# Generamos embeddings de las oraciones completas\n","emb_oracion_1 = modelo_embeddings.encode([oracion_1])\n","emb_oracion_2 = modelo_embeddings.encode([oracion_2])\n","\n","print(\"Embeddings de oraciones completas:\")\n","print(f\"Oraci√≥n 1 - Primeros 5 valores: {emb_oracion_1[0][:5]}\")\n","print(f\"Oraci√≥n 2 - Primeros 5 valores: {emb_oracion_2[0][:5]}\")\n","\n","# Calculamos la similitud entre las dos oraciones\n","similitud_oraciones = cosine_similarity(emb_oracion_1, emb_oracion_2)[0][0]\n","print(f\"\\nüìä Similitud entre las oraciones: {similitud_oraciones:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"comparison-results"},"source":["### Comparando los M√©todos\n","\n","Veamos qu√© tan diferentes son los embeddings generados por cada m√©todo:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"method-comparison","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357438,"user_tz":180,"elapsed":8,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"39522fe3-e181-4300-faee-4d6f94015112"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Resultados de la comparaci√≥n:\n","Similitud: Promedio de palabras vs Oraci√≥n 1: 0.424\n","Similitud: Promedio de palabras vs Oraci√≥n 2: 0.393\n","Similitud: Oraci√≥n 1 vs Oraci√≥n 2: 0.694\n","\n","üí° Observaciones:\n","- El m√©todo de promedio ve las oraciones como muy similares\n","- Esto se debe a que ignora el orden y el contexto\n","- Los embeddings de oraciones capturan mejor las diferencias de significado\n","- Consideran el contexto y la estructura gramatical\n"]}],"source":["# Comparamos el embedding promedio con los embeddings de oraciones\n","# Nota: necesitamos ajustar las dimensiones para la comparaci√≥n\n","embedding_promedio_reshaped = embedding_promedio.reshape(1, -1)\n","\n","sim_promedio_oracion1 = cosine_similarity(embedding_promedio_reshaped, emb_oracion_1)[0][0]\n","sim_promedio_oracion2 = cosine_similarity(embedding_promedio_reshaped, emb_oracion_2)[0][0]\n","\n","print(\"üîç Resultados de la comparaci√≥n:\")\n","print(f\"Similitud: Promedio de palabras vs Oraci√≥n 1: {sim_promedio_oracion1:.3f}\")\n","print(f\"Similitud: Promedio de palabras vs Oraci√≥n 2: {sim_promedio_oracion2:.3f}\")\n","print(f\"Similitud: Oraci√≥n 1 vs Oraci√≥n 2: {similitud_oraciones:.3f}\")\n","\n","print(\"\\nüí° Observaciones:\")\n","if abs(sim_promedio_oracion1 - sim_promedio_oracion2) < 0.1:\n","    print(\"- El m√©todo de promedio ve las oraciones como muy similares\")\n","    print(\"- Esto se debe a que ignora el orden y el contexto\")\n","else:\n","    print(\"- Incluso el promedio detecta algunas diferencias\")\n","\n","if similitud_oraciones < 0.8:\n","    print(\"- Los embeddings de oraciones capturan mejor las diferencias de significado\")\n","    print(\"- Consideran el contexto y la estructura gramatical\")"]},{"cell_type":"markdown","metadata":{"id":"practical-applications"},"source":["## Aplicaciones Pr√°cticas\n","\n","Los embeddings tienen muchas aplicaciones √∫tiles. Veamos algunas:"]},{"cell_type":"markdown","metadata":{"id":"search-application"},"source":["### 1. B√∫squeda Sem√°ntica\n","\n","Pod√©s buscar documentos por significado, no solo por palabras exactas:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"semantic-search","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357490,"user_tz":180,"elapsed":52,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"e33e2f4b-83d5-460c-a2c3-7c82ab73a002"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Buscando documentos relacionados con: 'quiero aprender a cocinar'\n","\n","üìä Resultados ordenados por relevancia:\n","1. [0.336] C√≥mo preparar una deliciosa pasta carbonara italiana\n","2. [0.272] Tutorial de programaci√≥n en Python para principiantes\n","3. [0.169] Receta tradicional de empanadas argentinas\n","4. [0.165] Introducci√≥n al aprendizaje autom√°tico y redes neuronales\n","5. [0.041] Los beneficios del ejercicio f√≠sico para la salud mental\n","6. [0.033] Beneficios de la meditaci√≥n y mindfulness para reducir estr√©s\n"]}],"source":["# Base de documentos de ejemplo\n","documentos = [\n","    \"C√≥mo preparar una deliciosa pasta carbonara italiana\",\n","    \"Los beneficios del ejercicio f√≠sico para la salud mental\",\n","    \"Tutorial de programaci√≥n en Python para principiantes\",\n","    \"Receta tradicional de empanadas argentinas\",\n","    \"Introducci√≥n al aprendizaje autom√°tico y redes neuronales\",\n","    \"Beneficios de la meditaci√≥n y mindfulness para reducir estr√©s\"\n","]\n","\n","# Consulta del usuario\n","consulta = \"quiero aprender a cocinar\"\n","\n","print(f\"üîç Buscando documentos relacionados con: '{consulta}'\")\n","print()\n","\n","# Generamos embeddings\n","emb_consulta = modelo_embeddings.encode([consulta])\n","emb_documentos = modelo_embeddings.encode(documentos)\n","\n","# Calculamos similitudes\n","similitudes = cosine_similarity(emb_consulta, emb_documentos)[0]\n","\n","# Ordenamos por similitud\n","indices_ordenados = np.argsort(similitudes)[::-1]\n","\n","print(\"üìä Resultados ordenados por relevancia:\")\n","for i, idx in enumerate(indices_ordenados):\n","    print(f\"{i+1}. [{similitudes[idx]:.3f}] {documentos[idx]}\")"]},{"cell_type":"markdown","metadata":{"id":"clustering-application"},"source":["### 2. Agrupamiento de Textos\n","\n","Pod√©s agrupar textos similares autom√°ticamente:"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"text-clustering","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357571,"user_tz":180,"elapsed":83,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"be6e01ea-6ada-45fb-8435-819f2f0f52b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Encontrando comentarios similares (similitud > 0.3):\n","\n","'Me encanta la pizza margherita'\n","  ‚îî‚îÄ [0.545] 'Las empanadas est√°n deliciosas'\n","  ‚îî‚îÄ [0.510] 'Prefiero el asado a la parrilla'\n","\n","'El f√∫tbol argentino es apasionante'\n","  ‚îî‚îÄ [0.545] 'Messi es el mejor jugador del mundo'\n","  ‚îî‚îÄ [0.342] 'Las empanadas est√°n deliciosas'\n","\n","'Python es un lenguaje muy √∫til'\n","  ‚îî‚îÄ [0.385] 'JavaScript es complicado a veces'\n","\n","'Las empanadas est√°n deliciosas'\n","  ‚îî‚îÄ [0.545] 'Me encanta la pizza margherita'\n","  ‚îî‚îÄ [0.419] 'Prefiero el asado a la parrilla'\n","  ‚îî‚îÄ [0.342] 'El f√∫tbol argentino es apasionante'\n","\n","'Messi es el mejor jugador del mundo'\n","  ‚îî‚îÄ [0.545] 'El f√∫tbol argentino es apasionante'\n","\n","'JavaScript es complicado a veces'\n","  ‚îî‚îÄ [0.385] 'Python es un lenguaje muy √∫til'\n","\n","'Prefiero el asado a la parrilla'\n","  ‚îî‚îÄ [0.510] 'Me encanta la pizza margherita'\n","  ‚îî‚îÄ [0.419] 'Las empanadas est√°n deliciosas'\n","\n"]}],"source":["# Comentarios de usuarios sobre diferentes temas\n","comentarios = [\n","    \"Me encanta la pizza margherita\",\n","    \"El f√∫tbol argentino es apasionante\",\n","    \"Python es un lenguaje muy √∫til\",\n","    \"Las empanadas est√°n deliciosas\",\n","    \"Messi es el mejor jugador del mundo\",\n","    \"JavaScript es complicado a veces\",\n","    \"Prefiero el asado a la parrilla\",\n","    \"La programaci√≥n requiere pr√°ctica\"\n","]\n","\n","# Generamos embeddings\n","emb_comentarios = modelo_embeddings.encode(comentarios)\n","\n","# Calculamos matriz de similitudes\n","matriz_similitudes = cosine_similarity(emb_comentarios)\n","\n","print(\"üîç Encontrando comentarios similares (similitud > 0.3):\")\n","print()\n","\n","for i in range(len(comentarios)):\n","    similares = []\n","    for j in range(len(comentarios)):\n","        if i != j and matriz_similitudes[i][j] > 0.3:\n","            similares.append((j, matriz_similitudes[i][j]))\n","\n","    if similares:\n","        similares.sort(key=lambda x: x[1], reverse=True)\n","        print(f\"'{comentarios[i]}'\")\n","        for j, sim in similares:\n","            print(f\"  ‚îî‚îÄ [{sim:.3f}] '{comentarios[j]}'\")\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"experimentation"},"source":["## Experiment√° con Tus Propios Textos\n","\n","Ahora es tu turno. Prob√° con textos que te interesen:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"experiment","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357587,"user_tz":180,"elapsed":15,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"a43f4c00-909f-4799-9ccf-d9ce6669ff2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Similitudes entre tus textos:\n","Texto 1 vs Texto 2: 0.642\n","  'Escrib√≠ aqu√≠ tu primer texto'\n","  'Y aqu√≠ tu segundo texto'\n","\n","Texto 1 vs Texto 3: 0.325\n","  'Escrib√≠ aqu√≠ tu primer texto'\n","  'Pod√©s agregar m√°s textos si quer√©s'\n","\n","Texto 2 vs Texto 3: 0.392\n","  'Y aqu√≠ tu segundo texto'\n","  'Pod√©s agregar m√°s textos si quer√©s'\n","\n"]}],"source":["# Cambi√° estos textos por los que quieras probar\n","mis_textos = [\n","    \"Escrib√≠ aqu√≠ tu primer texto\",\n","    \"Y aqu√≠ tu segundo texto\",\n","    \"Pod√©s agregar m√°s textos si quer√©s\"\n","]\n","\n","# Generamos embeddings y calculamos similitudes\n","mis_embeddings = modelo_embeddings.encode(mis_textos)\n","mis_similitudes = cosine_similarity(mis_embeddings)\n","\n","print(\"üîç Similitudes entre tus textos:\")\n","for i in range(len(mis_textos)):\n","    for j in range(i+1, len(mis_textos)):\n","        sim = mis_similitudes[i][j]\n","        print(f\"Texto {i+1} vs Texto {j+1}: {sim:.3f}\")\n","        print(f\"  '{mis_textos[i]}'\")\n","        print(f\"  '{mis_textos[j]}'\")\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"model-comparison-intro"},"source":["## Comparaci√≥n de Modelos: Prob√° los Mejores para Espa√±ol\n","\n","Ahora que entend√©s los conceptos b√°sicos, es hora de comparar diferentes modelos para ver cu√°l funciona mejor para tus necesidades. Incluimos los nuevos **EmbeddingGemma** de Google y otros modelos top-rankeados para espa√±ol."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"model-setup","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760828357588,"user_tz":180,"elapsed":8,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"c3af9d32-eaae-495d-b17e-3f764b2763c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["üéØ Modelos disponibles para comparaci√≥n:\n","‚Ä¢ Google EmbeddingGemma (Nuevo): google/embeddinggemma-300m\n","‚Ä¢ Multilingual MiniLM (R√°pido): paraphrase-multilingual-MiniLM-L12-v2\n","‚Ä¢ E5 Multilingual Large (Alta Calidad): intfloat/multilingual-e5-large\n","‚Ä¢ Sentence-BERT Espa√±ol: sentence-transformers/distiluse-base-multilingual-cased-v2\n","‚Ä¢ Universal Sentence Encoder: sentence-transformers/distiluse-base-multilingual-cased\n","‚Ä¢ BGE Multilingual (Estado del Arte): BAAI/bge-m3\n"]}],"source":["# Instalamos ipywidgets para el men√∫ desplegable interactivo\n","# !pip install ipywidgets\n","\n","import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","import time\n","import gc\n","\n","# Definimos los modelos a comparar\n","modelos_disponibles = {\n","    \"Google EmbeddingGemma (Nuevo)\": \"google/embeddinggemma-300m\",\n","    \"Multilingual MiniLM (R√°pido)\": \"paraphrase-multilingual-MiniLM-L12-v2\",\n","    \"E5 Multilingual Large (Alta Calidad)\": \"intfloat/multilingual-e5-large\",\n","    \"Sentence-BERT Espa√±ol\": \"sentence-transformers/distiluse-base-multilingual-cased-v2\",\n","    \"Universal Sentence Encoder\": \"sentence-transformers/distiluse-base-multilingual-cased\",\n","    \"BGE Multilingual (Estado del Arte)\": \"BAAI/bge-m3\"\n","}\n","\n","print(\"üéØ Modelos disponibles para comparaci√≥n:\")\n","for nombre, modelo_id in modelos_disponibles.items():\n","    print(f\"‚Ä¢ {nombre}: {modelo_id}\")"]},{"cell_type":"markdown","metadata":{"id":"interactive-menu"},"source":["### Men√∫ Interactivo de Comparaci√≥n\n","\n","Us√° el men√∫ desplegable para seleccionar un modelo y probar su rendimiento con oraciones en espa√±ol:"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"interactive-comparison","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["012356463bfd4113acc04302079c584c","5f5e8ba44f5440e6a78d2cd8ffa0941a","e9bffa6e33b04fd2a29b33ad6b2e0e78","773dae4aa9dc4278b81c2391f53bddf5","0ccf7201de294aadb8e24620ac02f215","d5e8df6ea7314c87834ba6b987967276","93eec0c659ca497cb1b9f0e2ecdd6db6","e59dee0193d744d897038422adbfbf51","d7f6e1308f804b5dae090e18dcac9cc9","6ad0b88723fc4ae7ba86fe1c7d00ad13","ec523b4da8cf4d6cb28fb10013f62f29","e8cfb1b236ab4f54b09c6600aa684858"]},"executionInfo":{"status":"ok","timestamp":1760828357623,"user_tz":180,"elapsed":35,"user":{"displayName":"JIMENEZ STEFANIA","userId":"01802828706422316718"}},"outputId":"584fe756-5809-4f23-c20e-4446c9356d68"},"outputs":[{"output_type":"stream","name":"stdout","text":["üéÆ Interfaz Interactiva de Comparaci√≥n de Modelos\n","\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(HBox(children=(Dropdown(description='Modelo:', layout=Layout(width='70%'), options=('Google Emb‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"012356463bfd4113acc04302079c584c"}},"metadata":{}}],"source":["# Oraciones de prueba en espa√±ol para evaluar los modelos\n","oraciones_prueba = [\n","    \"Me gusta mucho la comida argentina\",\n","    \"Disfruto de la gastronom√≠a de Argentina\",\n","    \"El f√∫tbol es mi deporte favorito\",\n","    \"Prefiero mirar partidos de soccer\",\n","    \"Necesito ayuda con mi tarea de matem√°ticas\",\n","    \"¬øPod√©s explicarme este problema de √°lgebra?\",\n","    \"El clima est√° muy lindo hoy\",\n","    \"Hace un d√≠a hermoso para salir\",\n","    \"Ma√±ana tengo un examen importante\",\n","    \"Voy al supermercado a comprar verduras\"\n","]\n","\n","# Creamos el widget de selecci√≥n\n","selector_modelo = widgets.Dropdown(\n","    options=list(modelos_disponibles.keys()),\n","    value=list(modelos_disponibles.keys())[0],\n","    description='Modelo:',\n","    style={'description_width': 'initial'},\n","    layout=widgets.Layout(width='70%')\n",")\n","\n","boton_evaluar = widgets.Button(\n","    description='üîç Evaluar Modelo',\n","    button_style='primary',\n","    layout=widgets.Layout(width='200px')\n",")\n","\n","area_resultados = widgets.Output()\n","\n","# Variable global para almacenar el modelo actual\n","modelo_actual = None\n","nombre_modelo_actual = None\n","\n","def cargar_modelo(nombre_modelo):\n","    \"\"\"Carga un modelo de manera segura con manejo de errores\"\"\"\n","    global modelo_actual, nombre_modelo_actual\n","\n","    modelo_id = modelos_disponibles[nombre_modelo]\n","\n","    try:\n","        # Liberamos memoria del modelo anterior\n","        if modelo_actual is not None:\n","            del modelo_actual\n","            gc.collect()\n","\n","        print(f\"‚è≥ Cargando {nombre_modelo}...\")\n","        start_time = time.time()\n","\n","        # Intentamos cargar el modelo\n","        modelo_actual = SentenceTransformer(modelo_id)\n","        nombre_modelo_actual = nombre_modelo\n","\n","        load_time = time.time() - start_time\n","        dimensiones = modelo_actual.get_sentence_embedding_dimension()\n","\n","        print(f\"‚úÖ Modelo cargado exitosamente\")\n","        print(f\"‚ö° Tiempo de carga: {load_time:.2f} segundos\")\n","        print(f\"üìä Dimensiones: {dimensiones}\")\n","\n","        return True\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error cargando {nombre_modelo}: {str(e)}\")\n","        print(f\"üí° Prob√° con otro modelo o verific√° tu conexi√≥n a internet\")\n","        return False\n","\n","def evaluar_modelo(button):\n","    \"\"\"Eval√∫a el modelo seleccionado con las oraciones de prueba\"\"\"\n","    with area_resultados:\n","        clear_output(wait=True)\n","\n","        nombre_seleccionado = selector_modelo.value\n","\n","        # Cargamos el modelo si no est√° cargado o cambi√≥\n","        if nombre_modelo_actual != nombre_seleccionado:\n","            if not cargar_modelo(nombre_seleccionado):\n","                return\n","\n","        print(f\"\\nüß™ Evaluando: {nombre_seleccionado}\")\n","        print(\"=\" * 50)\n","\n","        try:\n","            # Generamos embeddings\n","            start_time = time.time()\n","            embeddings = modelo_actual.encode(oraciones_prueba)\n","            inference_time = time.time() - start_time\n","\n","            print(f\"‚ö° Tiempo de inferencia: {inference_time:.2f} segundos\")\n","            print(f\"üìä {len(oraciones_prueba)} oraciones procesadas\")\n","            print(f\"üî¢ Dimensiones por embedding: {embeddings.shape[1]}\")\n","\n","            # Calculamos similitudes entre pares relacionados\n","            similitudes_esperadas = [\n","                (0, 1, \"Comida argentina\"),  # Comida argentina vs gastronom√≠a Argentina\n","                (2, 3, \"F√∫tbol/Soccer\"),     # F√∫tbol vs soccer\n","                (4, 5, \"Ayuda matem√°ticas\"), # Ayuda matem√°ticas vs √°lgebra\n","                (6, 7, \"Clima lindo\"),       # Clima lindo vs d√≠a hermoso\n","            ]\n","\n","            print(\"\\nüéØ Similitudes entre oraciones relacionadas:\")\n","            matriz_sim = cosine_similarity(embeddings)\n","\n","            total_similitud = 0\n","            for i, j, descripcion in similitudes_esperadas:\n","                sim = matriz_sim[i][j]\n","                total_similitud += sim\n","                print(f\"‚Ä¢ {descripcion}: {sim:.3f}\")\n","                print(f\"  '{oraciones_prueba[i]}'\")\n","                print(f\"  '{oraciones_prueba[j]}'\")\n","                print()\n","\n","            # Calculamos una m√©trica de calidad promedio\n","            calidad_promedio = total_similitud / len(similitudes_esperadas)\n","            print(f\"üìà Calidad promedio: {calidad_promedio:.3f}\")\n","\n","            # Interpretaci√≥n de la calidad\n","            if calidad_promedio > 0.7:\n","                print(\"üåü Excelente calidad para espa√±ol\")\n","            elif calidad_promedio > 0.5:\n","                print(\"üëç Buena calidad para espa√±ol\")\n","            elif calidad_promedio > 0.3:\n","                print(\"‚ö†Ô∏è Calidad moderada para espa√±ol\")\n","            else:\n","                print(\"‚ùå Calidad baja para espa√±ol\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Error durante la evaluaci√≥n: {str(e)}\")\n","\n","# Conectamos el bot√≥n a la funci√≥n\n","boton_evaluar.on_click(evaluar_modelo)\n","\n","# Mostramos los widgets\n","print(\"üéÆ Interfaz Interactiva de Comparaci√≥n de Modelos\")\n","print(\"\" * 50)\n","display(widgets.VBox([\n","    widgets.HBox([selector_modelo, boton_evaluar]),\n","    area_resultados\n","]))"]},{"cell_type":"markdown","metadata":{"id":"model-info"},"source":["### Informaci√≥n T√©cnica de los Modelos\n","\n","Ac√° ten√©s detalles t√©cnicos sobre cada modelo incluido en la comparaci√≥n:\n","\n","#### üÜï **Google EmbeddingGemma (Nuevo)**\n","- **Modelo**: `google/embeddinggemma-300m`\n","- **Par√°metros**: 300M\n","- **Especialidad**: √öltimo modelo de Google, optimizado para similitud sem√°ntica\n","- **Ventajas**: Arquitectura moderna, eficiente en memoria\n","\n","#### ‚ö° **Multilingual MiniLM (Recomendado para empezar)**\n","- **Modelo**: `paraphrase-multilingual-MiniLM-L12-v2`\n","- **Par√°metros**: ~118M\n","- **Especialidad**: Balance perfecto velocidad/calidad, excelente con espa√±ol\n","- **Ventajas**: R√°pido, confiable, bien documentado\n","\n","#### üåü **E5 Multilingual Large**\n","- **Modelo**: `intfloat/multilingual-e5-large`\n","- **Par√°metros**: ~560M\n","- **Especialidad**: Estado del arte en calidad multiling√ºe\n","- **Ventajas**: M√°xima calidad, muy bueno con espa√±ol\n","\n","#### üá™üá∏ **DistilRoBERTa Espa√±ol**\n","- **Modelo**: `sentence-transformers/paraphrase-spanish-distilroberta`\n","- **Par√°metros**: ~125M\n","- **Especialidad**: Entrenado espec√≠ficamente en espa√±ol\n","- **Ventajas**: Optimizado para espa√±ol, entiende jerga regional\n","\n","#### üîÑ **BGE Multilingual (Estado del Arte)**\n","- **Modelo**: `BAAI/bge-m3`\n","- **Par√°metros**: ~560M\n","- **Especialidad**: √öltimo estado del arte en embeddings multiling√ºes\n","- **Ventajas**: M√°ximo rendimiento, soporte para 100+ idiomas\n","\n","### üí° **Recomendaciones de Uso**\n","\n","- **Para aprendizaje**: Empez√° con Multilingual MiniLM\n","- **Para producci√≥n con calidad**: E5 Multilingual Large o BGE-M3\n","- **Para espa√±ol espec√≠fico**: DistilRoBERTa Espa√±ol\n","- **Para experimentar**: Google EmbeddingGemma (muy nuevo)\n","- **Para velocidad**: Multilingual MiniLM o Universal Sentence Encoder"]},{"cell_type":"markdown","metadata":{"id":"advanced-topics"},"source":["## Pr√≥ximos Pasos\n","\n","Ahora que entend√©s los conceptos b√°sicos, pod√©s explorar:\n","\n","1. **Otros modelos**: Prob√° modelos especializados en espa√±ol como `sentence-transformers/paraphrase-spanish-distilroberta`\n","2. **Fine-tuning**: Entren√° un modelo espec√≠fico para tu dominio\n","3. **Aplicaciones avanzadas**:\n","   - Sistemas de recomendaci√≥n\n","   - Clasificaci√≥n de textos\n","   - Traducci√≥n autom√°tica\n","   - Chatbots inteligentes\n","\n","### Modelos Recomendados para Espa√±ol\n","\n","```python\n","# Otros modelos que pod√©s probar:\n","modelos_espa√±ol = [\n","    'sentence-transformers/paraphrase-spanish-distilroberta',\n","    'sentence-transformers/distiluse-base-multilingual-cased',\n","    'hiiamsid/sentence_similarity_spanish_es',\n","]\n","```"]},{"cell_type":"markdown","metadata":{"id":"conclusion"},"source":["## Resumen\n","\n","En este cuaderno aprendiste:\n","\n","‚úÖ **Qu√© son los embeddings**: Representaciones num√©ricas del significado de textos\n","\n","‚úÖ **C√≥mo generarlos**: Usando modelos pre-entrenados de Hugging Face\n","\n","‚úÖ **Calcular similitudes**: Con la similitud coseno para medir qu√© tan parecidos son dos textos\n","\n","‚úÖ **Diferencias importantes**: Entre embeddings de palabras promediados y embeddings de oraciones contextuales\n","\n","‚úÖ **Aplicaciones pr√°cticas**: B√∫squeda sem√°ntica y agrupamiento de textos\n","\n","‚úÖ **Comparaci√≥n de modelos**: Herramientas para encontrar el mejor modelo para tus necesidades\n","\n","Los embeddings son una herramienta fundamental en el procesamiento de lenguaje natural moderno. ¬°Segu√≠ experimentando con diferentes textos y modelos para profundizar tu comprensi√≥n!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"1jjcj_NwnAUErXoHMGA8tCfP6XBcmlZf4","timestamp":1760827196985}],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"012356463bfd4113acc04302079c584c":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5f5e8ba44f5440e6a78d2cd8ffa0941a","IPY_MODEL_e9bffa6e33b04fd2a29b33ad6b2e0e78"],"layout":"IPY_MODEL_773dae4aa9dc4278b81c2391f53bddf5"}},"5f5e8ba44f5440e6a78d2cd8ffa0941a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ccf7201de294aadb8e24620ac02f215","IPY_MODEL_d5e8df6ea7314c87834ba6b987967276"],"layout":"IPY_MODEL_93eec0c659ca497cb1b9f0e2ecdd6db6"}},"e9bffa6e33b04fd2a29b33ad6b2e0e78":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_e8cfb1b236ab4f54b09c6600aa684858","msg_id":"","outputs":[]}},"773dae4aa9dc4278b81c2391f53bddf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ccf7201de294aadb8e24620ac02f215":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Google EmbeddingGemma (Nuevo)","Multilingual MiniLM (R√°pido)","E5 Multilingual Large (Alta Calidad)","Sentence-BERT Espa√±ol","Universal Sentence Encoder","BGE Multilingual (Estado del Arte)"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Modelo:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_e59dee0193d744d897038422adbfbf51","style":"IPY_MODEL_d7f6e1308f804b5dae090e18dcac9cc9"}},"d5e8df6ea7314c87834ba6b987967276":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"primary","description":"üîç Evaluar Modelo","disabled":false,"icon":"","layout":"IPY_MODEL_6ad0b88723fc4ae7ba86fe1c7d00ad13","style":"IPY_MODEL_ec523b4da8cf4d6cb28fb10013f62f29","tooltip":""}},"93eec0c659ca497cb1b9f0e2ecdd6db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e59dee0193d744d897038422adbfbf51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"70%"}},"d7f6e1308f804b5dae090e18dcac9cc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"6ad0b88723fc4ae7ba86fe1c7d00ad13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"200px"}},"ec523b4da8cf4d6cb28fb10013f62f29":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"e8cfb1b236ab4f54b09c6600aa684858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}